{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1cbb943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script chardetect.exe is installed in 'C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting medclip\n",
      "  Downloading MedCLIP-0.0.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from medclip) (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (from medclip) (2.2.2)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from medclip) (10.3.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from medclip) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from medclip) (4.66.4)\n",
      "Collecting wget (from medclip)\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: nltk>=3.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from medclip) (3.8.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from medclip) (1.4.2)\n",
      "Collecting textaugment>=1.3.4 (from medclip)\n",
      "  Downloading textaugment-2.0.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting timm>=0.6.11 (from medclip)\n",
      "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.4 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/42.4 kB ? eta -:--:--\n",
      "     ------------------------------------ - 41.0/42.4 kB 495.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.4/42.4 kB 412.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: torch>=1.12.1 in c:\\users\\arooj\\appdata\\roaming\\python\\python312\\site-packages (from medclip) (2.4.1)\n",
      "Collecting torchvision>=0.13.1 (from medclip)\n",
      "  Downloading torchvision-0.19.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting transformers>=4.23.1 (from medclip)\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.7->medclip) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.7->medclip) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.7->medclip) (2023.10.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.2->medclip) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.1.2->medclip) (2.2.0)\n",
      "Requirement already satisfied: gensim>=4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from textaugment>=1.3.4->medclip) (4.3.2)\n",
      "Collecting textblob (from textaugment>=1.3.4->medclip)\n",
      "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting googletrans>=2 (from textaugment>=1.3.4->medclip)\n",
      "  Downloading googletrans-3.0.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from timm>=0.6.11->medclip) (6.0.1)\n",
      "Collecting huggingface_hub (from timm>=0.6.11->medclip)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm>=0.6.11->medclip)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.12.1->medclip) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.12.1->medclip) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.12.1->medclip) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.12.1->medclip) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.12.1->medclip) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.12.1->medclip) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.12.1->medclip) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers>=4.23.1->medclip) (23.2)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers>=4.23.1->medclip)\n",
      "  Downloading tokenizers-0.20.0-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->medclip) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->medclip) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->medclip) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->medclip) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->medclip) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->medclip) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->medclip) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->medclip) (2024.7.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim>=4.0->textaugment>=1.3.4->medclip) (5.2.1)\n",
      "Collecting httpx==0.13.3 (from googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading hstspreload-2024.10.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip) (1.3.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->medclip)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans>=2->textaugment>=1.3.4->medclip)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->medclip) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.12.1->medclip) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.12.1->medclip) (1.3.0)\n",
      "Downloading MedCLIP-0.0.3-py3-none-any.whl (27 kB)\n",
      "Downloading textaugment-2.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.2/2.3 MB 3.1 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.8/2.3 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.9/2.3 MB 10.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 10.5 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.19.1-cp312-cp312-win_amd64.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 39.9 MB/s eta 0:00:00\n",
      "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 2.6/9.9 MB 83.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 74.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.1/9.9 MB 72.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 63.3 MB/s eta 0:00:00\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.1/55.1 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.4/133.4 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.0/65.0 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "   ---------------------------------------- 0.0/436.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 436.4/436.4 kB 28.4 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "   ---------------------------------------- 0.0/286.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 286.3/286.3 kB ? eta 0:00:00\n",
      "Downloading tokenizers-0.20.0-cp312-none-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.0/2.3 MB 64.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.3 MB 64.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.3 MB 64.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.3 MB 64.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.3 MB 64.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.3 MB 64.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.1/2.3 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.3 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.3 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.3 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.3 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.2/2.3 MB 1.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.3 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.3 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.4/2.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.4/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.5/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.7/2.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.8/2.3 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.0/2.3 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.1/2.3 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.3/2.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.3/2.3 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
      "   ---------------------------------------- 0.0/626.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 626.3/626.3 kB 19.3 MB/s eta 0:00:00\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2024.10.1-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 38.6 MB/s eta 0:00:00\n",
      "Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.6/53.6 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: wget, googletrans\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=2e85bdb025cd70f2588658f7127170b4799045f7d4155dd9faca4c8bb494cd96\n",
      "  Stored in directory: c:\\users\\arooj\\appdata\\local\\pip\\cache\\wheels\\01\\46\\3b\\e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15780 sha256=67c944ff0513f2db289f5ad5ca04acbe66c7f1fc0639741744e5cf530ef8ba67\n",
      "  Stored in directory: c:\\users\\arooj\\appdata\\local\\pip\\cache\\wheels\\42\\7b\\d6\\83f2d86a7a395f572a917a76605eef432f46345e3383b92ec0\n",
      "Successfully built wget googletrans\n",
      "Installing collected packages: wget, rfc3986, hyperframe, hpack, h11, chardet, safetensors, idna, hstspreload, h2, httpcore, torchvision, textblob, huggingface_hub, httpx, tokenizers, timm, googletrans, transformers, textaugment, medclip\n",
      "Successfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.10.1 httpcore-0.9.1 httpx-0.13.3 huggingface_hub-0.25.1 hyperframe-5.2.0 idna-2.10 medclip-0.0.3 rfc3986-1.5.0 safetensors-0.4.5 textaugment-2.0.0 textblob-0.18.0.post0 timm-1.0.9 tokenizers-0.20.0 torchvision-0.19.1 transformers-4.45.2 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install medclip\n",
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "from medclip import MedCLIPModel, MedCLIPVisionModelViT\n",
    "from medclip import MedCLIPProcessor\n",
    "from medclip import PromptClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c500a330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\clip\\feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f96957ceda48e492115736a82c5fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Arooj\\.cache\\huggingface\\hub\\models--emilyalsentzer--Bio_ClinicalBERT. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f725c1c0b24cd0ad09ee6ddd65d602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cdc770a84e41ce84ac13cb1118181f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python312\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Arooj\\.cache\\huggingface\\hub\\models--microsoft--swin-tiny-patch4-window7-224. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762c50dc5b1546f5b8d1a2ae6bda1b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83df806d35064335ad2508e019b709c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python312\\site-packages\\medclip\\modeling_medclip.py:147: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(os.path.join(checkpoint, constants.WEIGHTS_NAME))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/MedCLIP/checkpoints/vision_text_pretrain/25000\\\\pytorch_model.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# init models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m processor \u001b[38;5;241m=\u001b[39m MedCLIPProcessor()\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m MedCLIPModel(vision_cls\u001b[38;5;241m=\u001b[39mMedCLIPVisionModelViT, checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/MedCLIP/checkpoints/vision_text_pretrain/25000\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m clf \u001b[38;5;241m=\u001b[39m PromptClassifier(model, ensemble\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m clf\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\medclip\\modeling_medclip.py:147\u001b[0m, in \u001b[0;36mMedCLIPModel.__init__\u001b[1;34m(self, vision_cls, checkpoint, vision_checkpoint, logit_scale_init_value)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit_scale \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mlogit_scale_init_value)))\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(checkpoint, constants\u001b[38;5;241m.\u001b[39mWEIGHTS_NAME))\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload model weight from:\u001b[39m\u001b[38;5;124m'\u001b[39m, checkpoint)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/MedCLIP/checkpoints/vision_text_pretrain/25000\\\\pytorch_model.bin'"
     ]
    }
   ],
   "source": [
    "# init models\n",
    "processor = MedCLIPProcessor()\n",
    "model = MedCLIPModel(vision_cls=MedCLIPVisionModelViT, checkpoint='./data/MedCLIP/checkpoints/vision_text_pretrain/25000')\n",
    "clf = PromptClassifier(model, ensemble=True)\n",
    "clf.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3bc5dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arooj\\AppData\\Roaming\\Python\\Python312\\site-packages\\medclip\\dataset.py:265: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  splitter = re.compile(\"[0-9]+\\.+[^0-9]\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MedCLIPFeatureExtractor' object has no attribute 'convert_rgb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Arooj/thesis/Ryan_multimodularity data/MedCLIP/example_data/view1_frontal.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m processor(images\u001b[38;5;241m=\u001b[39mimage, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# prepare input prompt texts\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmedclip\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_chexpert_class_prompts, process_class_prompts\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\transformers\\models\\clip\\processing_clip.py:109\u001b[0m, in \u001b[0;36mCLIPProcessor.__call__\u001b[1;34m(self, text, images, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 109\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_processor(images, return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mimage_processor_kwargs)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     encoding[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpixel_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m image_features\u001b[38;5;241m.\u001b[39mpixel_values\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\medclip\\dataset.py:105\u001b[0m, in \u001b[0;36mMedCLIPFeatureExtractor.__call__\u001b[1;34m(self, images, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# transformations (convert rgb + resizing + center cropping + normalization)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_convert_rgb:\n\u001b[1;32m--> 105\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_rgb(image) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_pad_square:\n\u001b[0;32m    108\u001b[0m     images \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_img(image,min_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MedCLIPFeatureExtractor' object has no attribute 'convert_rgb'"
     ]
    }
   ],
   "source": [
    "# prepare input image\n",
    "from PIL import Image\n",
    "image = Image.open('C:/Users/Arooj/thesis/Ryan_multimodularity data/MedCLIP/example_data/view1_frontal.jpg')\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# prepare input prompt texts\n",
    "from medclip.prompts import generate_chexpert_class_prompts, process_class_prompts\n",
    "\n",
    "cls_prompts = process_class_prompts(generate_chexpert_class_prompts(n=10))\n",
    "inputs['prompt_inputs'] = cls_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16d7238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logits': tensor([[0.5154, 0.4119, 0.2831, 0.2441, 0.4588]], device='cuda:0',\n",
      "       grad_fn=<StackBackward0>), 'class_names': ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Pleural Effusion']}\n"
     ]
    }
   ],
   "source": [
    "output = clf(**inputs)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
